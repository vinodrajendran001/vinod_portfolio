<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Aerial Image Segmentation · Vinod</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="In this post, I will be illustrating my attempt on how deep learning methods can be used to perform aerial image segmentation using CITY-OSM dataset."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Aerial Image Segmentation · Vinod"/><meta property="og:type" content="website"/><meta property="og:url" content="https://vinodrajendran001.github.io/vinod_portfolio/blog/2020/05/25/aerial-seg"/><meta property="og:description" content="In this post, I will be illustrating my attempt on how deep learning methods can be used to perform aerial image segmentation using CITY-OSM dataset."/><meta property="og:image" content="https://vinodrajendran001.github.io/vinod_portfolio/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://vinodrajendran001.github.io/vinod_portfolio/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/vinod_portfolio/img/profile.png"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://vinodrajendran001.github.io/vinod_portfolio/blog/atom.xml" title="Vinod Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://vinodrajendran001.github.io/vinod_portfolio/blog/feed.xml" title="Vinod Blog RSS Feed"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-156234948-1', 'auto');
              ga('send', 'pageview');
            </script><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/vinod_portfolio/js/scrollSpy.js"></script><link rel="stylesheet" href="/vinod_portfolio/css/main.css"/><script src="/vinod_portfolio/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/vinod_portfolio/"><img class="logo" src="/vinod_portfolio/img/profile.png" alt="Vinod"/><h2 class="headerTitleWithLogo">Vinod</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/vinod_portfolio/index" target="_self">Home</a></li><li class=""><a href="/vinod_portfolio/docs/proj_ind" target="_self">Projects</a></li><li class="siteNavGroupActive"><a href="/vinod_portfolio/blog/" target="_self">Blog</a></li><li class=""><a href="/vinod_portfolio/contact" target="_self">Contact</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Recent Posts</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">Recent Posts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/vinod_portfolio/blog/2020/09/20/siamese-NN-one-shot-learning">Siamese Neural Networks for One-shot Image Recognition</a></li><li class="navListItem"><a class="navItem" href="/vinod_portfolio/blog/2020/08/01/stochastic-signal-analysis">Machine Learning for Stochastic Signal Analysis</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/vinod_portfolio/blog/2020/05/25/aerial-seg">Aerial Image Segmentation</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer postContainer blogContainer"><div class="wrapper"><div class="lonePost"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/vinod_portfolio/blog/2020/05/25/aerial-seg">Aerial Image Segmentation</a></h1><p class="post-meta">May 25, 2020</p><div class="authorBlock"><p class="post-authorName"><a target="_blank" rel="noreferrer noopener">Vinod</a></p></div></header><div><span><p>In this post, I will be illustrating my attempt on how deep learning methods can be used to perform aerial image segmentation using CITY-OSM dataset.</p>
<!--truncate-->
<p>The sequence of tasks are arranged in following manner</p>
<ol>
<li>Download dataset</li>
<li>Exploration of Dataset</li>
<li>Process Image</li>
<li>Prepare Dataset</li>
<li>Build a segmentation model</li>
<li>Evaluate the model</li>
<li>Prediction</li>
</ol>
<p>Aerial imagery dataset is collected from Google Maps and labels are obtained from Open Street Maps (OSM). The labels include road, building and background.</p>
<table>
<thead>
<tr><th style="text-align:center">Satellite Image</th><th style="text-align:center">Label</th><th style="text-align:center">Overlay</th></tr>
</thead>
<tbody>
<tr><td style="text-align:center"><img width="150" height="150" src="../../../../img/tokyo1_image.png"></td><td style="text-align:center"><img width="150" height="150" src="../../../../img/tokyo1_labels.png"></td><td style="text-align:center"><img width="150" height="150" src="../../../../img/tokyo1_overlap.png"></td></tr>
</tbody>
</table>
<p>The available cities in CITY-OSM dataset are Berlin, Chicago, Paris, Potsdam, Tokyo and Zurich. I have automated the process to download the dataset and extract labels from the user defined cities. While processing the dataset, I split every single image into 4x4 grid and reisze into 300x300 pixels. For each image, the labels are categorized as 0: building red, 1 road blue, 2 BG white. The additional noisy pixels are assigned to 2 BG white. Finally, based on the processed images the train and test set are prepared.</p>
<p>I decided to go with U-Net for 2 reasons</p>
<ul>
<li>The UNet combines the location information from the downsampling path to finally obtain a general information combining localisation and context, which is necessary to predict a good segmentation map.</li>
<li>Since it has shown success in many segmentation tasks, it could potentially serve as a benchmark for my next approach (need to do literature review).</li>
</ul>
<h3><a class="anchor" aria-hidden="true" id="u-net"></a><a href="#u-net" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>U-Net</h3>
<p>Arxiv Link: <a href=https://arxiv.org/abs/1505.04597>Convolutional Networks for Biomedical Image Segmentation</a></p>
<ul>
<li>UNet is a fully convolutional network(FCN) that does image segmentation. Its goal is to predict each pixel's class.</li>
<li>UNet is built upon the FCN and modified in a way that it yields better segmentation in medical imaging.</li>
</ul>
<p>UNet Architecture has 3 parts:</p>
<ol>
<li>The Contracting/Downsampling Path</li>
<li>Bottleneck</li>
<li>The Expanding/Upsampling Path</li>
</ol>
<h4><a class="anchor" aria-hidden="true" id="downsampling-path"></a><a href="#downsampling-path" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Downsampling Path:</h4>
<ul>
<li>It consists of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2 for downsampling.</li>
<li>At each downsampling step we double the number of feature channels.</li>
</ul>
<h4><a class="anchor" aria-hidden="true" id="upsampling-path"></a><a href="#upsampling-path" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Upsampling Path:</h4>
<ul>
<li>Every step in the expansive path consists of an upsampling of the feature map followed by a 2x2 convolution (“up-convolution”), a concatenation with the correspondingly feature map from the downsampling path, and two 3x3 convolutions, each followed by a ReLU.</li>
</ul>
<p><strong>Skip Connection</strong>: The skip connection from the downsampling path are concatenated with feature map during upsampling path. These skip connection provide local information to global information while upsampling.</p>
<p><strong>Final Layer</strong>: At the final layer a 1x1 convolution is used to map each feature vector to the desired number of classes.</p>
<p>I used a variant of U-Net (quarter the features maps than the original) to build the segmentation model.</p>
<p>From the berlin dataset, it was clearly visible that the classes (Building, Road and BG) are not balanced. To overcome it, I applied weight factor ['BG': 1, 'Road': 2, 'BG': 0.5]. These weights can be used to give more importance to the imbalanced classes.</p>
<p>I compute the Intersection over Union (IoU) for building, road and background to quantify the percent overlap between the target mask and our prediction output.</p>
<h3><a class="anchor" aria-hidden="true" id="results"></a><a href="#results" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Results</h3>
<p>Dataset used: Berlin</p>
<p>No. of Test set images: 640</p>
<p>Building IoU on test set =0.6401</p>
<p>Road IoU on test set = 0.4409</p>
<p>BG IoU on test set = 0.6520</p>
<p>mIoU on test set = 0.5776</p>
<p>Frequency weighted IoU on test set = 0.6413</p>
<p>Pixel accuracy on test set = 0.7691</p>
<table>
<thead>
<tr><th style="text-align:center">Satellite Image</th><th style="text-align:center">Label</th><th style="text-align:center">Predicted</th></tr>
</thead>
<tbody>
<tr><td style="text-align:center"><img width="150" height="150" src="../../../../img/tokyo1_image.png"></td><td style="text-align:center"><img width="150" height="150" src="../../../../img/tokyo1_labels.png"></td><td style="text-align:center"><img width="150" height="150" src="../../../../img/predict_tokyo1_mask.png"></td></tr>
</tbody>
</table>
<p>Although the pixel-wise accuracy looks reasonable, IoU for each class can be increased further.</p>
<h3><a class="anchor" aria-hidden="true" id="next-steps"></a><a href="#next-steps" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Next steps:</h3>
<ol>
<li><p>Increase the number of iterations/epochs. The above result is just based on 10 epochs (due to limited compute resource).</p></li>
<li><p>Adding image augmentation like zooming and changing angles, rotation etc to provide wide situations for training. This could help in creating the model that is more smart to recognize the buildings, roads and BG in different situations. And it also increases the number of images in data which directly proportional to the good prediction of result.</p></li>
<li><p>Replace the variant of U-Net with original U-Net architecture.</p></li>
<li><p>Build U-Net with backbone architecures (VGG, ResNet, DenseNET, EfficientNet, etc.) as a encoder part. In this way, pretrained weights can be used to fine-tune the model.</p></li>
</ol>
<p>The complete code and procedure to reproduce can be found in my <a href=https://github.com/vinodrajendran001/aerial_segmentation>GitHub repo</a>.</p>
</span></div></div><div class="blogSocialSection"></div></div><div class="blog-recent"><a class="button" href="/vinod_portfolio/blog/">Recent Posts</a></div></div></div><nav class="onPageNav"></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/vinod_portfolio/" class="nav-home"><img src="/vinod_portfolio/img/profile.png" alt="Vinod" width="66" height="58"/></a><div><h5>Get in touch</h5><a href="/vinod_portfolio/contact">Contact</a></div><div><h5>Community</h5><a href="https://stackoverflow.com/users/4232441/vinod-prime" target="_blank" rel="noreferrer noopener">Stack Overflow</a></div><div><h5>More</h5><a href="https://github.com/vinodrajendran001">GitHub</a><a href="https://www.linkedin.com/in/vinod-rajendran-506536a6">LinkedIn</a></div></section><section class="copyright">Copyright © 2020 Vinod</section></footer></div></body></html>